# weights_path: can be .weights (openCV) or .pth (Pytorch)
# n_cpu: number of cpu workers, 0 means main thread

car_locator:
  model_cfg: models/data/yolov3.cfg
  weights_path: models/data/yolov3.weights
  class_path: models/data/coco.names
  conf_thres: 0.5
  nms_thres: 0.4
  n_cpu: 0
  img_size: 416
  pred_mode: torch
  batch_size: 1

car_locator_trt:
  model_path: models/data/yolov4_coco-1_416_fp16.engine
  class_path: models/data/coco.names
  n_classes: 80
  conf_thres: 0.5
  nms_thres: 0.4
  input_size: !!python/tuple [416, 416]
  max_batch_size: 1

lpr:
  pad_x: 0.1
  pad_y: 0.1

plate_detector:
  model_cfg: models/data/yolov3_plate_191204.cfg
  weights_path: models/data/plate_191204.weights
  class_path: models/data/detector_classes.names
  conf_thres: 0.5
  nms_thres: 0.4
  # batch_size: 8
  n_cpu: 0
  img_size: 416
  pred_mode: cv2

plate_detector_trt:
  model_path: models/data/yolov4_plate-8_416_fp16.engine
  class_path: models/data/detector_classes.names
  n_classes: 1
  conf_thres: 0.5
  nms_thres: 0.4
  input_size: !!python/tuple [416, 416]
  max_batch_size: 8

segmentator:
  model_cfg: models/data/yolov3_char_seg_191219.cfg
  weights_path: models/data/char_seg_191219.weights
  class_path: models/data/segmentator_classes.names
  conf_thres: 0.5
  nms_thres: 0.4
  # batch_size: 8
  n_cpu: 0
  img_size: 416
  char_line_threshold: 0.5
  pred_mode: cv2

segmentator_trt:
  model_path: models/data/yolov4_seg-8_320_fp16.engine
  class_path: models/data/segmentator_classes.names
  n_classes: 1
  conf_thres: 0.5
  nms_thres: 0.4
  input_size: !!python/tuple [320, 320] # (h, w)
  max_batch_size: 8
  char_line_threshold: 0.5
  contrast: 3.5 # 0 to not add contrast

char_recognizer:
  weights_path: models/data/char_recog_9687.pth
  # inverse_char_dict_path: models.data.char_dict
  # inverse_char_dict: inverse_char_dict
  inverse_char_dict: models/data/char_dict.yaml
  # conf_thres: 0.5
  img_size: 16
